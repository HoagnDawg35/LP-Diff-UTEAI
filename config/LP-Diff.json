{
    "name": "LP-Diff",
    "dataset_path": "data/icpr_train", // train or val
    "gpu_ids": [
        0
    ],
    "path": { //set the path
        "log": "logs",
        "tb_logger": "tb_logger",
        "results": "results",
        "checkpoint": "checkpoint",
        //pretrain model or training state
        "resume_state": "H:/ICPR2026/LP-Diff/LP-Diff-kaggle/experiments/LP-Diff_251224_042735/checkpoint/I10000_E9"
    },
    "datasets": {
        "train": {
            "name": "MDLP",
            "mode": "LRHR",
            "dataroot": "H:/ICPR2026/LP-Diff-UTEAI/data/icpr_train",
            "width": 224,
            "height": 112,
            "batch_size": 20,
            "num_workers": 0
        },
        "val": {
            "name": "MDLP",
            "mode": "LRHR",
            "width": 224,
            "height": 112,
            "dataroot": "H:/ICPR2026/LP-Diff-UTEAI/data/icpr_train"
        }
    },
    "model": {
        "finetune_norm": false,
        "unet": {
            "in_channel": 6,
            "out_channel": 3,
            "inner_channel": 64,
            "channel_multiplier": [
                1,
                2,
                4,
                8,
                8
            ],
            "attn_res": [
                16
            ],
            "res_blocks": 2,
            "dropout": 0.1
        },
        "beta_schedule": { // use munual beta_schedule for acceleration
            "train": {
                "schedule": "linear",
                "n_timestep": 1000,
                "linear_start": 1e-6,
                "linear_end": 1e-2
            },
            "val": {
                "schedule": "linear",
                "n_timestep": 1000, // amount of iteration during inference
                "linear_start": 1e-6,
                "linear_end": 1e-2
            }
        },
        "diffusion": {
            "image_size": 128,
            "channels": 3, //sample channel
            "conditional": true // unconditional generation or unconditional generation(super_resolution)
        }
    },
    "train": {
        "use_prerain_MTA": false, // use the pretrained MTA model
        "resume_training": false, // whether resume training
        "MTA": "H:/ICPR2026/LP-Diff/LP-Diff-kaggle/experiments/LP-Diff_251224_042735/checkpoint/I10000_E9_gen.pth",
        "n_iter": 800000,
        "val_freq": 2e4,
        "save_checkpoint_freq": 1e4,
        "print_freq": 200,
        "optimizer": {
            "type": "adam",
            "lr": 1e-4
        },
        // ocr loss
        "ocr_opt": {
            "use_ocr_loss": true,
            "ocr_loss_weight": 0.01,
            "ocr_ckpt_path": "H:/ICPR2026/DiffTSR/ckpt/transocr.pth"
        },
        "ema_scheduler": { // not used now
            "step_start_ema": 5000,
            "update_ema_every": 1,
            "ema_decay": 0.9999
        }
    },
    "wandb": {
        "project": "LP-Diff"
    }
}